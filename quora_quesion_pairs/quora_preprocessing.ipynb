{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_IN_PATH = './quora_data/'\n",
    "train_data = pd.read_csv(DATA_IN_PATH + 'train.csv', encoding='utf-8')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 중복인 경우(pos)와 아닌 경우(neg)로 나눈 후 중복이 아닌 개수가 비슷하도록 데이터를 다시 뽑음\n",
    "train_pos_data = train_data.loc[train_data['is_duplicate'] == 1]\n",
    "train_neg_data = train_data.loc[train_data['is_duplicate'] == 0]\n",
    "\n",
    "# EDA를 통해 중복이 아닌 데이터가 중복인 데이터보다 많음을 확인했음\n",
    "class_difference = len(train_neg_data) - len(train_pos_data)\n",
    "sample_frac = 1 - (class_difference / len(train_neg_data))\n",
    "\n",
    "train_neg_data = train_neg_data.sample(frac = sample_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 질문 개수: 149263\n",
      "중복이 아닌 질문 개수: 149263\n"
     ]
    }
   ],
   "source": [
    "# 중복인 질문의 개수와 중복이 아닌 질문의 개수가 이제 동일해짐\n",
    "print('중복 질문 개수: {}'.format(len(train_pos_data)))\n",
    "print('중복이 아닌 질문 개수: {}'.format(len(train_neg_data)))\n",
    "\n",
    "# 학습을 위해 두 데이터를 하나로 합침\n",
    "train_data = pd.concat([train_neg_data, train_pos_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구두점 및 기호를 제거하고 모든 문자를 소문자로 바꾸는 전처리\n",
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "change_filter = re.compile(FILTERS)\n",
    "\n",
    "questions1 = [str(s) for s in train_data['question1']]\n",
    "questions2 = [str(s) for s in train_data['question2']]\n",
    "\n",
    "filtered_questions1 = []\n",
    "filtered_questions2 = []\n",
    "\n",
    "# 모든 기호들을 제거하고 모든 문자를 소문자로 바꿈\n",
    "for q in questions1:\n",
    "    filtered_questions1.append(re.sub(change_filter, \"\", q).lower())\n",
    "\n",
    "for q in questions2:\n",
    "    filtered_questions2.append(re.sub(change_filter, \"\", q).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 토크나이징\n",
    "# 토크나이징 객체는 두 질문 텍스트를 합친 리스트에 대해 적용하지만, 토크나이징은 각 질문에 대해 따로 진행\n",
    "\n",
    "# 토크나이징 객체 생성\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(filtered_questions1 + filtered_questions2)\n",
    "\n",
    "# 각 질문 텍스트에 대해 토크나이징 후 각 단어를 인덱스로 변환\n",
    "questions1_sequence = tokenizer.texts_to_sequences(filtered_questions1)\n",
    "questions2_sequence = tokenizer.texts_to_sequences(filtered_questions2)\n",
    "\n",
    "# 전체 데이터 길이를 맞추기 위해 패딩 처리\n",
    "# MAX_SEQUENCE_LENGTH 값(EDA에서 확인한 단어 개수의 상위 99퍼센트인 31)보다 긴 데이터는 자르고, 짧은 데이터는 default padding value인 0을 뒤에서부터 채워넣음\n",
    "MAX_SEQUENCE_LENGTH = 31\n",
    "q1_data = pad_sequences(questions1_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "q2_data = pad_sequences(questions2_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data: (298526, 31)\n",
      "Shape of question2 data: (298526, 31)\n",
      "Shape of label: (298526,)\n",
      "Words in index: 76467\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 데이터의 크기를 확인\n",
    "# 단어 사전을 생성, 단어의 개수를 확인해보기 위해 패딩 처리된 부분은 제외\n",
    "word_vocab = {}\n",
    "word_vocab = tokenizer.word_index\n",
    "word_vocab[\"<PAD\"] = 0\n",
    "\n",
    "labels = np.array(train_data[\"is_duplicate\"], dtype=int)\n",
    "\n",
    "print('Shape of question1 data: {}'.format(q1_data.shape))\n",
    "print('Shape of question2 data: {}'.format(q2_data.shape))\n",
    "print('Shape of label: {}'.format(labels.shape))\n",
    "print('Words in index: {}'.format(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전과 단어 개수를 딕셔너리 형태로 저장\n",
    "data_configs = {}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전처리한 각 데이터들을 저장\n",
    "DATA_OUT_PATH = './quora_data/'\n",
    "TRAIN_Q1_DATA = 'q1_train.npy'\n",
    "TRAIN_Q2_DATA = 'q2_train.npy'\n",
    "TRAIN_LABEL_DATA = 'label_train.npy'\n",
    "DATA_CONFIGS = 'data_configs.npy'\n",
    "\n",
    "np.save(open(DATA_OUT_PATH + TRAIN_Q1_DATA, 'wb'), q1_data)\n",
    "np.save(open(DATA_OUT_PATH + TRAIN_Q2_DATA, 'wb'), q2_data)\n",
    "np.save(open(DATA_OUT_PATH + TRAIN_LABEL_DATA, 'wb'), labels)\n",
    "\n",
    "json.dump(data_configs, open(DATA_OUT_PATH + DATA_CONFIGS, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/childult-programmer/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# 위의 과정을 평가 데이터에 대해서도 동일하게 진행\n",
    "test_data = pd.read_csv(DATA_IN_PATH + 'test.csv', encoding='utf-8')\n",
    "valid_ids = [type(x) == int for x in test_data.test_id]\n",
    "test_data = test_data[valid_ids].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions1 = [str(s) for s in test_data['question1']]\n",
    "test_questions2 = [str(s) for s in test_data['question2']]\n",
    "\n",
    "filtered_test_questions1 = list()\n",
    "filtered_test_questions2 = list()\n",
    "\n",
    "for q in test_questions1:\n",
    "     filtered_test_questions1.append(re.sub(change_filter, \"\", q).lower())\n",
    "        \n",
    "for q in test_questions2:\n",
    "     filtered_test_questions2.append(re.sub(change_filter, \"\", q).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions1_sequence = tokenizer.texts_to_sequences(filtered_test_questions1)\n",
    "test_questions2_sequence = tokenizer.texts_to_sequences(filtered_test_questions2)\n",
    "\n",
    "test_q1_data = pad_sequences(test_questions1_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_q2_data = pad_sequences(test_questions2_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data: (2345796, 31)\n",
      "Shape of question2 data:(2345796, 31)\n",
      "Shape of ids: (2345796,)\n"
     ]
    }
   ],
   "source": [
    "test_id = np.array(test_data['test_id'])\n",
    "\n",
    "print('Shape of question1 data: {}'.format(test_q1_data.shape))\n",
    "print('Shape of question2 data:{}'.format(test_q2_data.shape))\n",
    "print('Shape of ids: {}'.format(test_id.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리한 테스트 텍스트 데이터를 저장\n",
    "TEST_Q1_DATA = 'test_q1.npy'\n",
    "TEST_Q2_DATA = 'test_q2.npy'\n",
    "TEST_ID_DATA = 'test_id.npy'\n",
    "\n",
    "np.save(open(DATA_IN_PATH + TEST_Q1_DATA, 'wb'), test_q1_data)\n",
    "np.save(open(DATA_IN_PATH + TEST_Q2_DATA , 'wb'), test_q2_data)\n",
    "np.save(open(DATA_IN_PATH + TEST_ID_DATA , 'wb'), test_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
