{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리한 학습 데이터를 불러옴\n",
    "DATA_IN_PATH  = './data/'\n",
    "DATA_OUT_PATH = './submission/'\n",
    "\n",
    "TRAIN_INPUT_DATA = 'train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "train_input = np.load(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'rb'))\n",
    "train_label = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 고정\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 하이퍼파라미터 정의\n",
    "model_name = 'rnn_classifier'\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "        'vocab_size': prepro_configs['vocab_size'],\n",
    "        'embedding_dimension': 100,\n",
    "        'dropout_rate': 0.2,\n",
    "        'lstm_dimension': 150,\n",
    "        'dense_dimension': 150,\n",
    "        'output_dimension': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(RNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "        self.embedding = Embedding(input_dim=kargs['vocab_size'],\n",
    "                                   output_dim=kargs['embedding_dimension'])\n",
    "        self.lstm_1_layer = LSTM(kargs['lstm_dimension'], return_sequences=True)\n",
    "        self.lstm_2_layer = LSTM(kargs['lstm_dimension'])\n",
    "        self.dropout = Dropout(kargs['dropout_rate'])\n",
    "        self.fc1 = Dense(units=kargs['dense_dimension'], activation='tanh')\n",
    "        self.fc2 = Dense(units=kargs['output_dimension'], activation='sigmoid')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lstm_1_layer(x)\n",
    "        x = self.lstm_2_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = RNNClassifier(**kargs)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./submission/rnn_classifier -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5169\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54120, saving model to ./submission/rnn_classifier/weights.h5\n",
      "176/176 [==============================] - 120s 680ms/step - loss: 0.6924 - accuracy: 0.5169 - val_loss: 0.6875 - val_accuracy: 0.5412\n",
      "Epoch 2/5\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.6590\n",
      "Epoch 00002: val_accuracy improved from 0.54120 to 0.78960, saving model to ./submission/rnn_classifier/weights.h5\n",
      "176/176 [==============================] - 121s 685ms/step - loss: 0.6163 - accuracy: 0.6590 - val_loss: 0.5700 - val_accuracy: 0.7896\n",
      "Epoch 3/5\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7306\n",
      "Epoch 00003: val_accuracy did not improve from 0.78960\n",
      "176/176 [==============================] - 122s 691ms/step - loss: 0.5772 - accuracy: 0.7306 - val_loss: 0.6619 - val_accuracy: 0.5856\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_accuracy did not improve from 0.78960, epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
