{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAVER 영화 리뷰 데이터 분석 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈들을 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Dropout, Dense, GlobalMaxPooling1D\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA시 전처리한 데이터를 불러옴\n",
    "DATA_IN_PATH = './data/'\n",
    "\n",
    "INPUT_TRAIN_DATA = 'nsmc_train_input.npy'\n",
    "INPUT_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs_kr.json'\n",
    "\n",
    "train_input = np.load(open(DATA_IN_PATH + INPUT_TRAIN_DATA, 'rb'))\n",
    "train_input = pad_sequences(train_input, maxlen=train_input.shape[1])\n",
    "train_label = np.load(open(DATA_IN_PATH + INPUT_LABEL_DATA, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 하이퍼파라미터 정의\n",
    "model_name = 'cnn_classifier_kr'\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "        'vocab_size': prepro_configs['vocab_size'],\n",
    "        'embedding_dimension': 128,\n",
    "        'num_filters': 100,\n",
    "        'dropout_rate': 0.2,\n",
    "        'hidden_dimension': 150,\n",
    "        'output_dimension': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 생성하는 클래스를 정의\n",
    "class CNNClassifier(Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(CNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "        self.embedding = Embedding(input_dim=kargs['vocab_size'],\n",
    "                                  output_dim=kargs['embedding_dimension'])\n",
    "        self.conv_list = [Conv1D(filters=kargs['num_filters'],\n",
    "                                kernel_size=kernel_size,\n",
    "                                padding='valid',\n",
    "                                activation='relu',\n",
    "                                kernel_constraint=MaxNorm(max_value=3.))\n",
    "                         for kernel_size in [3,4,5]]\n",
    "        self.max_pooling = GlobalMaxPooling1D()\n",
    "        self.dropout = Dropout(kargs['dropout_rate'])\n",
    "        self.fc1 = Dense(units=kargs['hidden_dimension'],\n",
    "                        activation='relu', kernel_constraint=MaxNorm(max_value=3.))\n",
    "        self.fc2 = Dense(units=kargs['output_dimension'],\n",
    "                        activation='sigmoid', kernel_constraint=MaxNorm(max_value=3.))\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = tf.concat([self.max_pooling(conv(x)) for conv in self.conv_list], axis=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = CNNClassifier(**kargs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./submission/cnn_classifier_kr -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting 방지\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8002\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82807, saving model to ./submission/cnn_classifier_kr/weights.h5\n",
      "1055/1055 [==============================] - 45s 43ms/step - loss: 0.4217 - accuracy: 0.8002 - val_loss: 0.3802 - val_accuracy: 0.8281\n",
      "Epoch 2/5\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8700\n",
      "Epoch 00002: val_accuracy improved from 0.82807 to 0.82913, saving model to ./submission/cnn_classifier_kr/weights.h5\n",
      "1055/1055 [==============================] - 45s 42ms/step - loss: 0.3046 - accuracy: 0.8700 - val_loss: 0.3875 - val_accuracy: 0.8291\n",
      "Epoch 3/5\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9132\n",
      "Epoch 00003: val_accuracy did not improve from 0.82913\n",
      "1055/1055 [==============================] - 45s 42ms/step - loss: 0.2136 - accuracy: 0.9132 - val_loss: 0.4564 - val_accuracy: 0.8230\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                   validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1s 803us/step - loss: 0.3899 - accuracy: 0.8273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38986945152282715, 0.8272799849510193]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터를 불러옴\n",
    "DATA_OUT_PATH = './submission/'\n",
    "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
    "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
    "SAVE_FILE_NAME = 'weights.h5'\n",
    "\n",
    "test_input = np.load(open(DATA_IN_PATH + INPUT_TEST_DATA, 'rb'))\n",
    "test_input = pad_sequences(test_input, maxlen=test_input.shape[1])\n",
    "test_label_data = np.load(open(DATA_IN_PATH + LABEL_TEST_DATA, 'rb'))\n",
    "\n",
    "# 모델 테스트\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NAME))\n",
    "model.evaluate(test_input, test_label_data) # accuracy : 0.8273"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
